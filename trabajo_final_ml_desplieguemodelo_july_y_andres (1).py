# -*- coding: utf-8 -*-
"""Trabajo Final_ML_DespliegueModelo_July y Andres.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K69qJhBUzhNH85w1vWLXMuat-mdyF88X
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit

# prompt: Haz todo el despliegue anterior en streamlit
import streamlit as st
import pandas as pd
import joblib
import os

# Function to preprocess the data
def preprocess_data(df, encoder, scaler):
    df['Desccripción Origen'] = df['Desccripción Origen'].astype('category')
    df['Corredor'] = df['Corredor'].astype('category')
    df['Nombre clase de transporte'] = df['Nombre clase de transporte'].astype('category')
    df['Dia de la semana '] = df['Dia de la semana '].astype('category')
    df['Tipo vehiculo'] = df['Tipo vehiculo'].astype('category')

    df = df.drop(['Cant caja grande', 'Cant caja mini', 'Cant caja pequeña', 'Cant caja mediana', 'Dia', 'Dia de la semana', 'Semana','Nº de transporte'], axis=1)
    df = df.drop('Tipo vehiculo', axis=1)

    # Apply
    #numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    #scaled_data = scaler.transform(df[numeric_cols])
    #scaled_df = pd.DataFrame(scaled_data, columns=numeric_cols)

    # Select non-numerical columns from the original DataFrame
    #non_numeric_cols = df.select_dtypes(exclude=['float64', 'int64']).columns
    #df_non_numeric = df[non_numeric_cols]

    # Reset index of both dataframes before concatenation to ensure proper alignment
    #df_non_numeric = df_non_numeric.reset_index(drop=True)
    #scaled_df = scaled_df.reset_index(drop=True)

    # Concatenate the non-numerical and scaled numerical DataFrames
    #df_scaled_combined = pd.concat([df_non_numeric, scaled_df], axis=1)

    scaled_data = scaler.transform(df)
    scaled_df = pd.DataFrame(scaled_data, columns=scaler.get_feature_names_out())

    # Apply
    encoded_data = encoder.transform(scaled_df)
    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out())
    encoded_df.columns = encoded_df.columns.str.replace('cat__', '')
    encoded_df.columns = encoded_df.columns.str.replace('remainder__', '')
    df=encoded_df.columns
    return df

# Load the pre-trained models and transformers
# Assuming your models and transformers are in a directory named 'saved_models'
# in the same directory as your Streamlit app or accessible via a path.
try:
    encoder = joblib.load('trained_model/onehot_encoder.pkl')
    scaler = joblib.load('trained_model/scaler.pkl')
    mlp_model = joblib.load('trained_model/best_mlp_classifier_model.pkl')
    label_encoder= joblib.load('trained_model/label_encoder.pkl')
except FileNotFoundError:
    st.error("Error: Model files not found. Make sure 'saved_models' directory with required files exists.")
    st.stop()

# Streamlit App Title
st.title("Predicción de Tipo de Vehiculo")

st.write("""
Esta aplicación predice el tipo de vehículo que deben usar según la tipologia de los productos y el destino de entrega.
""")

# File uploader for the user to upload their data
uploaded_file = st.file_uploader("Sube tu archivo Excel (solo .xlsx)", type=["xlsx"])

if uploaded_file is not None:
    try:
        # Read the uploaded Excel file into a pandas DataFrame
        df = pd.read_excel(uploaded_file)

        st.subheader("Datos cargados:")
        st.write(df.head())

        # Preprocess the data
        st.subheader("Datos preprocesados:")
        processed_df = preprocess_data(df.copy(), encoder, scaler)
        st.write(processed_df.head())

        # Make predictions using different models
        st.subheader("Predicciones:")

        # Red Neuronal
        mlp_predictions = mlp_model.predict(processed_df)
        df['Predicted_MLP'] = mlp_predictions

        # Transform the numerical predictions back to original labels
        Predicted_labels_MLP = label_encoder.inverse_transform(mlp_predictions)

        # Add the predicted labels to the DataFrame
        df['Predicted_Label_MLP'] = Predicted_labels_MLP

        st.write("Predicciones (MLP Classifier):")
        st.write(df[['Desccripción Origen','Corredor','Nombre clase de transporte','Vol caja grande', 'Vol caja mediana','Vol caja mini','Vol caja pequeña','Numero de paradas','Predicted_MLP','Predicted_Label_MLP']].head())


    except Exception as e:
        st.error(f"Ocurrió un error al procesar el archivo: {e}")
